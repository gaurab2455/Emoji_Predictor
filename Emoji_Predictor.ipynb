{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji_Prdictor\n",
    "- We provide our model with some sentences which then predicts the emoji most associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and see data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./emojify_data.csv', header=None)\n",
    "test_data = pd.read_csv('./test_emoji.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is your favorite baseball game</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I cooked meat</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stop messing around</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want chinese food</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Let us go play baseball</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0  1   2     3\n",
       "0          French macaroon is so tasty  4 NaN   NaN\n",
       "1                     work is horrible  3 NaN   NaN\n",
       "2                           I am upset  3 NaN   [3]\n",
       "3                       throw the ball  1 NaN   [2]\n",
       "4                            Good joke  2 NaN   NaN\n",
       "5  what is your favorite baseball game  1 NaN   NaN\n",
       "6                        I cooked meat  4 NaN   NaN\n",
       "7                  stop messing around  3 NaN   NaN\n",
       "8                  I want chinese food  4 NaN   NaN\n",
       "9              Let us go play baseball  1 NaN   NaN"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a very nice raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a nice present\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he is a good friend\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am upset\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We had such a lovely dinner tonight\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>where is the food\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stop making this joke ha ha ha\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0  1\n",
       "0                        I want to eat\\t  4\n",
       "1                    he did not answer\\t  3\n",
       "2             he got a very nice raise\\t  2\n",
       "3            she got me a nice present\\t  2\n",
       "4             ha ha ha it was so funny\\t  2\n",
       "5                  he is a good friend\\t  2\n",
       "6                           I am upset\\t  3\n",
       "7  We had such a lovely dinner tonight\\t  2\n",
       "8                    where is the food\\t  4\n",
       "9       Stop making this joke ha ha ha\\t  2"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 4)\n"
     ]
    }
   ],
   "source": [
    "Data = data.values\n",
    "test_data = test_data.values\n",
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183,)\n",
      "(183,)\n",
      "(56,)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "X_train = Data[:,0]\n",
    "Y_train = Data[:,1]\n",
    "X_test = test_data[:,0]\n",
    "Y_test = test_data[:,1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\t 4\n",
      "he did not answer\t 3\n",
      "he got a very nice raise\t 2\n",
      "she got me a nice present\t 2\n",
      "ha ha ha it was so funny\t 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_test[i],Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ❤️\n",
      "1 ⚾\n",
      "2 😄\n",
      "3 😞\n",
      "4 🍴\n"
     ]
    }
   ],
   "source": [
    "emoji_dict = { 0 : \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "               1 : \":baseball:\",\n",
    "               2 : \":smile:\",\n",
    "               3 : \":disappointed:\",\n",
    "               4 : \":fork_and_knife:\"\n",
    "             }\n",
    "for ix in emoji_dict.keys():\n",
    "    print(ix,emoji.emojize(emoji_dict[ix],use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French macaroon is so tasty 🍴\n",
      "work is horrible 😞\n",
      "I am upset 😞\n",
      "throw the ball ⚾\n",
      "Good joke 😄\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i], emoji.emojize(emoji_dict[Y_train[i]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pre-trained weights using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.6B.50d.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5586e-01,  5.2130e-01, -6.1070e-01, -3.0131e-01,  9.4862e-01,\n",
       "       -3.1539e-01, -5.9831e-01,  1.2188e-01, -3.1943e-02,  5.5695e-01,\n",
       "       -1.0621e-01,  6.3399e-01, -4.7340e-01, -7.5895e-02,  3.8247e-01,\n",
       "        8.1569e-02,  8.2214e-01,  2.2220e-01, -8.3764e-03, -7.6620e-01,\n",
       "       -5.6253e-01,  6.1759e-01,  2.0292e-01, -4.8598e-02,  8.7815e-01,\n",
       "       -1.6549e+00, -7.7418e-01,  1.5435e-01,  9.4823e-01, -3.9520e-01,\n",
       "        3.7302e+00,  8.2855e-01, -1.4104e-01,  1.6395e-02,  2.1115e-01,\n",
       "       -3.6085e-02, -1.5587e-01,  8.6583e-01,  2.6309e-01, -7.1015e-01,\n",
       "       -3.6770e-02,  1.8282e-03, -1.7704e-01,  2.7032e-01,  1.1026e-01,\n",
       "        1.4133e-01, -5.7322e-02,  2.7207e-01,  3.1305e-01,  9.2771e-01])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['good'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input to the RNN model will be a 3-D volume with dimensions batch_size, \n",
    "# dimension_of_each_word(50 here) and the maximum possible length of each sentence\n",
    "# which can be varied depending on input. Here we are using relatively smaller\n",
    "# sentences so we use 10. In input to the RNN model will be 3-D vector of dimension\n",
    "# (50,50,10) considering a batch size of 50\n",
    "def embedding_output(X):\n",
    "    maxLen = 10\n",
    "    emb_dim = 50\n",
    "    embedding_out = np.zeros((X.shape[0], maxLen,emb_dim))\n",
    "    \n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix] = X[ix].split()\n",
    "        \n",
    "        for ij in range(len(X[ix])):\n",
    "            # go to every word in the current (ix) sentence\n",
    "            try:\n",
    "                embedding_out[ix][ij] = embeddings_index[X[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij] = np.zeros((50,))\n",
    "    \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix_train = embedding_output(X_train)\n",
    "embeddings_matrix_test = embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['French', 'macaroon', 'is', 'so', 'tasty']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_matrix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 5)\n",
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=5)\n",
    "Y_test = to_categorical(Y_test, num_classes=5)\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 1.6028 - accuracy: 0.2329 - val_loss: 1.5507 - val_accuracy: 0.3514\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 1.5662 - accuracy: 0.2808 - val_loss: 1.5198 - val_accuracy: 0.2973\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 0s 334us/step - loss: 1.5210 - accuracy: 0.3288 - val_loss: 1.4985 - val_accuracy: 0.3243\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 1.4951 - accuracy: 0.3562 - val_loss: 1.4856 - val_accuracy: 0.3243\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 1.4676 - accuracy: 0.3356 - val_loss: 1.4713 - val_accuracy: 0.3243\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 1.4502 - accuracy: 0.3836 - val_loss: 1.4502 - val_accuracy: 0.3243\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 1.4364 - accuracy: 0.3562 - val_loss: 1.4280 - val_accuracy: 0.2973\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 1.3698 - accuracy: 0.4521 - val_loss: 1.4114 - val_accuracy: 0.3784\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 1.3309 - accuracy: 0.4863 - val_loss: 1.3985 - val_accuracy: 0.3514\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 1.2478 - accuracy: 0.5822 - val_loss: 1.3870 - val_accuracy: 0.2973\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 1.1740 - accuracy: 0.6164 - val_loss: 1.3752 - val_accuracy: 0.3514\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 1.1156 - accuracy: 0.6370 - val_loss: 1.3549 - val_accuracy: 0.3243\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 1.0607 - accuracy: 0.6301 - val_loss: 1.3923 - val_accuracy: 0.3514\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.9775 - accuracy: 0.6096 - val_loss: 1.3499 - val_accuracy: 0.3243\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.9164 - accuracy: 0.6918 - val_loss: 1.3145 - val_accuracy: 0.3514\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.8435 - accuracy: 0.7123 - val_loss: 1.3163 - val_accuracy: 0.4054\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.7764 - accuracy: 0.7260 - val_loss: 1.2283 - val_accuracy: 0.3514\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.7333 - accuracy: 0.7397 - val_loss: 1.1775 - val_accuracy: 0.3514\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.7128 - accuracy: 0.7534 - val_loss: 1.1571 - val_accuracy: 0.4324\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.6460 - accuracy: 0.7808 - val_loss: 1.1062 - val_accuracy: 0.4324\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.5976 - accuracy: 0.7740 - val_loss: 1.1335 - val_accuracy: 0.5135\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.5327 - accuracy: 0.8151 - val_loss: 1.0180 - val_accuracy: 0.5676\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.5108 - accuracy: 0.8288 - val_loss: 0.9466 - val_accuracy: 0.6757\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.4979 - accuracy: 0.8356 - val_loss: 0.9042 - val_accuracy: 0.6216\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.4373 - accuracy: 0.8630 - val_loss: 1.0362 - val_accuracy: 0.5676\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.4110 - accuracy: 0.8219 - val_loss: 1.0850 - val_accuracy: 0.5405\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.3574 - accuracy: 0.8699 - val_loss: 1.1435 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.3116 - accuracy: 0.9041 - val_loss: 1.1665 - val_accuracy: 0.6216\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.3046 - accuracy: 0.8767 - val_loss: 1.2395 - val_accuracy: 0.5676\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.3744 - accuracy: 0.8699 - val_loss: 1.1319 - val_accuracy: 0.5946\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.3053 - accuracy: 0.9041 - val_loss: 1.1392 - val_accuracy: 0.5946\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.2868 - accuracy: 0.8767 - val_loss: 1.2170 - val_accuracy: 0.5676\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.3121 - accuracy: 0.9110 - val_loss: 1.1639 - val_accuracy: 0.6216\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.2645 - accuracy: 0.9041 - val_loss: 1.0755 - val_accuracy: 0.6757\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.2039 - accuracy: 0.9315 - val_loss: 1.1067 - val_accuracy: 0.6486\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 1.2451 - val_accuracy: 0.6216\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.3292 - accuracy: 0.8836 - val_loss: 1.1554 - val_accuracy: 0.5676\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.2078 - accuracy: 0.9521 - val_loss: 1.0623 - val_accuracy: 0.6216\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.1679 - accuracy: 0.9384 - val_loss: 1.0535 - val_accuracy: 0.7297\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.1940 - accuracy: 0.9315 - val_loss: 1.0282 - val_accuracy: 0.6757\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.2139 - accuracy: 0.9178 - val_loss: 1.0240 - val_accuracy: 0.6216\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.1777 - accuracy: 0.9315 - val_loss: 1.0389 - val_accuracy: 0.7027\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.1722 - accuracy: 0.9247 - val_loss: 1.0921 - val_accuracy: 0.5946\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.1527 - accuracy: 0.9521 - val_loss: 1.2946 - val_accuracy: 0.5405\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.1814 - accuracy: 0.9452 - val_loss: 1.2816 - val_accuracy: 0.5946\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.2177 - accuracy: 0.9315 - val_loss: 1.1486 - val_accuracy: 0.6486\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.1857 - accuracy: 0.9247 - val_loss: 1.1743 - val_accuracy: 0.5676\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.2093 - accuracy: 0.9384 - val_loss: 1.2578 - val_accuracy: 0.5405\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.1384 - accuracy: 0.9452 - val_loss: 1.2419 - val_accuracy: 0.6216\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.1526 - accuracy: 0.9521 - val_loss: 1.2073 - val_accuracy: 0.6757\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.1411 - accuracy: 0.9589 - val_loss: 1.5751 - val_accuracy: 0.6216\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.2199 - accuracy: 0.9452 - val_loss: 1.2463 - val_accuracy: 0.6216\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.1623 - accuracy: 0.9521 - val_loss: 1.2226 - val_accuracy: 0.6216\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 0s 332us/step - loss: 0.1035 - accuracy: 0.9658 - val_loss: 1.1286 - val_accuracy: 0.6757\n",
      "Epoch 55/100\n",
      "146/146 [==============================] - 0s 348us/step - loss: 0.1536 - accuracy: 0.9384 - val_loss: 1.0383 - val_accuracy: 0.7297\n",
      "Epoch 56/100\n",
      "146/146 [==============================] - 0s 316us/step - loss: 0.1215 - accuracy: 0.9589 - val_loss: 1.0921 - val_accuracy: 0.6216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "146/146 [==============================] - 0s 289us/step - loss: 0.1048 - accuracy: 0.9795 - val_loss: 1.1453 - val_accuracy: 0.5676\n",
      "Epoch 58/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.1169 - accuracy: 0.9658 - val_loss: 1.0031 - val_accuracy: 0.7027\n",
      "Epoch 59/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0923 - accuracy: 0.9795 - val_loss: 1.0816 - val_accuracy: 0.6757\n",
      "Epoch 60/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.1154 - accuracy: 0.9726 - val_loss: 1.0701 - val_accuracy: 0.6757\n",
      "Epoch 61/100\n",
      "146/146 [==============================] - 0s 271us/step - loss: 0.0861 - accuracy: 0.9658 - val_loss: 1.2930 - val_accuracy: 0.5676\n",
      "Epoch 62/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0796 - accuracy: 0.9795 - val_loss: 1.1876 - val_accuracy: 0.6486\n",
      "Epoch 63/100\n",
      "146/146 [==============================] - 0s 296us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.1828 - val_accuracy: 0.6757\n",
      "Epoch 64/100\n",
      "146/146 [==============================] - 0s 309us/step - loss: 0.1200 - accuracy: 0.9452 - val_loss: 1.2256 - val_accuracy: 0.6486\n",
      "Epoch 65/100\n",
      "146/146 [==============================] - 0s 303us/step - loss: 0.1052 - accuracy: 0.9726 - val_loss: 1.5229 - val_accuracy: 0.5946\n",
      "Epoch 66/100\n",
      "146/146 [==============================] - 0s 305us/step - loss: 0.0994 - accuracy: 0.9521 - val_loss: 1.2267 - val_accuracy: 0.6486\n",
      "Epoch 67/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0533 - accuracy: 0.9863 - val_loss: 1.2758 - val_accuracy: 0.6486\n",
      "Epoch 68/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0613 - accuracy: 0.9863 - val_loss: 1.2754 - val_accuracy: 0.6757\n",
      "Epoch 69/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0473 - accuracy: 0.9932 - val_loss: 1.3235 - val_accuracy: 0.5946\n",
      "Epoch 70/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4781 - val_accuracy: 0.5676\n",
      "Epoch 71/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0508 - accuracy: 0.9795 - val_loss: 1.3006 - val_accuracy: 0.6216\n",
      "Epoch 72/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.6757\n",
      "Epoch 73/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 1.2592 - val_accuracy: 0.6757\n",
      "Epoch 74/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.3087 - val_accuracy: 0.6486\n",
      "Epoch 75/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0277 - accuracy: 0.9932 - val_loss: 1.3597 - val_accuracy: 0.6486\n",
      "Epoch 76/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 1.2545 - val_accuracy: 0.6757\n",
      "Epoch 77/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.2280 - val_accuracy: 0.7297\n",
      "Epoch 78/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0351 - accuracy: 0.9932 - val_loss: 1.2318 - val_accuracy: 0.7297\n",
      "Epoch 79/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0540 - accuracy: 0.9795 - val_loss: 1.3743 - val_accuracy: 0.5946\n",
      "Epoch 80/100\n",
      "146/146 [==============================] - 0s 260us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.5029 - val_accuracy: 0.5946\n",
      "Epoch 81/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.3858 - val_accuracy: 0.5946\n",
      "Epoch 82/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0379 - accuracy: 0.9932 - val_loss: 1.3349 - val_accuracy: 0.7297\n",
      "Epoch 83/100\n",
      "146/146 [==============================] - 0s 260us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.5020 - val_accuracy: 0.6486\n",
      "Epoch 84/100\n",
      "146/146 [==============================] - 0s 260us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.6192 - val_accuracy: 0.7027\n",
      "Epoch 85/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0326 - accuracy: 0.9932 - val_loss: 1.4972 - val_accuracy: 0.7027\n",
      "Epoch 86/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.4529 - val_accuracy: 0.6757\n",
      "Epoch 87/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.4076 - val_accuracy: 0.7027\n",
      "Epoch 88/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.7297\n",
      "Epoch 89/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4188 - val_accuracy: 0.7027\n",
      "Epoch 90/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.6757\n",
      "Epoch 91/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3905 - val_accuracy: 0.6757\n",
      "Epoch 92/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.7027\n",
      "Epoch 93/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.7568\n",
      "Epoch 94/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 1.3256 - val_accuracy: 0.7568\n",
      "Epoch 95/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.4727 - val_accuracy: 0.7027\n",
      "Epoch 96/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.5851 - val_accuracy: 0.6486\n",
      "Epoch 97/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.6216\n",
      "Epoch 98/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 1.3772 - val_accuracy: 0.7027\n",
      "Epoch 99/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 1.4186 - val_accuracy: 0.6486\n",
      "Epoch 100/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.7382 - val_accuracy: 0.6216\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(embeddings_matrix_train, Y_train, epochs=100,batch_size=64,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 0 2 0 3 0 4 2 1 3 3 3 1 3 3 2 3 4 0 0 4 0 3 3 1 0 2 0 0 1 3 2 0 1 2\n",
      " 4 4 2 3 2 0 1 2 0 3 2 3 3 3 0 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(embeddings_matrix_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 196us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9837713582175118, 0.7857142686843872]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 0s 362us/step - loss: 0.0477 - accuracy: 0.9932 - val_loss: 1.5589 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55893, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 0s 458us/step - loss: 0.0132 - accuracy: 0.9932 - val_loss: 1.5483 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55893 to 1.54828, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      " 64/146 [============>.................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurab\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 321us/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 1.5616 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54828\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4501 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.54828 to 1.45006, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6619 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.45006\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 0s 300us/step - loss: 0.0534 - accuracy: 0.9795 - val_loss: 1.4318 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.45006 to 1.43183, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.1083 - accuracy: 0.9658 - val_loss: 1.5734 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.43183\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 0s 334us/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 2.2710 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.43183\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.1742 - accuracy: 0.9247 - val_loss: 1.5773 - val_accuracy: 0.5946\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.43183\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0439 - accuracy: 0.9795 - val_loss: 1.3781 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.43183 to 1.37809, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 0s 341us/step - loss: 0.0282 - accuracy: 0.9932 - val_loss: 1.4245 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.37809\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 0s 334us/step - loss: 0.0448 - accuracy: 0.9932 - val_loss: 1.5060 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.37809\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 1.4744 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.37809\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.4562 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.37809\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.5676\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.37809\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 1.5738 - val_accuracy: 0.5405\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.37809\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.5820 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.37809\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 1.5193 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.37809\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4954 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.37809\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.4989 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.37809\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.37809\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5619 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.37809\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5393 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.37809\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.37809\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.4432 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.37809\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.37809\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.4112 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.37809\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.37809\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 0s 260us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3943 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.37809\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3808 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.37809\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4073 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.37809\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.37809\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5172 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.37809\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.37809\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.37809\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.37809\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 0s 273us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5090 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.37809\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.5014 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.37809\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4894 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.37809\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.37809\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4630 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.37809\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 0s 266us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.37809\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.37809\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 273us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.37809\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5718 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.37809\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.37809\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.37809\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.37809\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6879 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.37809\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7243 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.37809\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7488 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.37809\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.37809\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6976 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.37809\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.6918 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.37809\n",
      "Epoch 55/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.37809\n",
      "Epoch 56/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.37809\n",
      "Epoch 57/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.37809\n",
      "Epoch 58/100\n",
      "146/146 [==============================] - 0s 342us/step - loss: 0.0132 - accuracy: 0.9932 - val_loss: 1.8048 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.37809\n",
      "Epoch 59/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7384 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.37809\n",
      "Epoch 60/100\n",
      "146/146 [==============================] - 0s 321us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7556 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.37809\n",
      "Epoch 61/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.7930 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.37809\n",
      "Epoch 62/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.37809\n",
      "Epoch 63/100\n",
      "146/146 [==============================] - 0s 304us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7882 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.37809\n",
      "Epoch 64/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6840 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.37809\n",
      "Epoch 65/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.37809\n",
      "Epoch 66/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.5656 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.37809\n",
      "Epoch 67/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.37809\n",
      "Epoch 68/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.37809\n",
      "Epoch 69/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.37809\n",
      "Epoch 70/100\n",
      "146/146 [==============================] - 0s 342us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6511 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.37809\n",
      "Epoch 71/100\n",
      "146/146 [==============================] - 0s 383us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6894 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.37809\n",
      "Epoch 72/100\n",
      "146/146 [==============================] - 0s 383us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7684 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.37809\n",
      "Epoch 73/100\n",
      "146/146 [==============================] - 0s 376us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0004 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.37809\n",
      "Epoch 74/100\n",
      "146/146 [==============================] - 0s 348us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.0220 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.37809\n",
      "Epoch 75/100\n",
      "146/146 [==============================] - 0s 348us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.37809\n",
      "Epoch 76/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0131 - accuracy: 0.9932 - val_loss: 1.5960 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.37809\n",
      "Epoch 77/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6754 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.37809\n",
      "Epoch 78/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.37809\n",
      "Epoch 79/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.5611 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.37809\n",
      "Epoch 80/100\n",
      "146/146 [==============================] - 0s 287us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5528 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.37809\n",
      "Epoch 81/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5443 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.37809\n",
      "Epoch 82/100\n",
      "146/146 [==============================] - 0s 328us/step - loss: 0.0101 - accuracy: 0.9932 - val_loss: 1.4516 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.37809\n",
      "Epoch 83/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4830 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.37809\n",
      "Epoch 84/100\n",
      "146/146 [==============================] - 0s 301us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4749 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.37809\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 287us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.37809\n",
      "Epoch 86/100\n",
      "146/146 [==============================] - 0s 314us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.37809\n",
      "Epoch 87/100\n",
      "146/146 [==============================] - 0s 267us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5320 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.37809\n",
      "Epoch 88/100\n",
      "146/146 [==============================] - 0s 275us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5465 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.37809\n",
      "Epoch 89/100\n",
      "146/146 [==============================] - 0s 341us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5251 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.37809\n",
      "Epoch 90/100\n",
      "146/146 [==============================] - 0s 329us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.7838\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.37809\n",
      "Epoch 91/100\n",
      "146/146 [==============================] - 0s 275us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4748 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.37809\n",
      "Epoch 92/100\n",
      "146/146 [==============================] - 0s 280us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.5004 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.37809\n",
      "Epoch 93/100\n",
      "146/146 [==============================] - 0s 275us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5326 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.37809\n",
      "Epoch 94/100\n",
      "146/146 [==============================] - 0s 363us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5644 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.37809\n",
      "Epoch 95/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5944 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.37809\n",
      "Epoch 96/100\n",
      "146/146 [==============================] - 0s 294us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6237 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.37809\n",
      "Epoch 97/100\n",
      "146/146 [==============================] - 0s 307us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6219 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.37809\n",
      "Epoch 98/100\n",
      "146/146 [==============================] - 0s 261us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6158 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.37809\n",
      "Epoch 99/100\n",
      "146/146 [==============================] - 0s 359us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6140 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.37809\n",
      "Epoch 100/100\n",
      "146/146 [==============================] - 0s 319us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6123 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.37809\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss',verbose=True,save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10)\n",
    "hist = model.fit(embeddings_matrix_train, Y_train, epochs=100,batch_size=64,shuffle=True, validation_split=0.2, callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 219us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7397586107254028, 0.8035714030265808]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "🍴\n",
      "🍴\n",
      "he did not answer\n",
      "😞\n",
      "😞\n",
      "he got a very nice raise\n",
      "😄\n",
      "😄\n",
      "she got me a nice present\n",
      "😄\n",
      "❤️\n",
      "ha ha ha it was so funny\n",
      "😄\n",
      "😄\n",
      "he is a good friend\n",
      "😄\n",
      "❤️\n",
      "I am upset\n",
      "😞\n",
      "😞\n",
      "We had such a lovely dinner tonight\n",
      "😄\n",
      "❤️\n",
      "where is the food\n",
      "🍴\n",
      "🍴\n",
      "Stop making this joke ha ha ha\n",
      "😄\n",
      "😄\n",
      "where is the ball\n",
      "⚾\n",
      "⚾\n",
      "work is hard\n",
      "😞\n",
      "😞\n",
      "This girl is messing with me\n",
      "😞\n",
      "😞\n",
      "are you serious\n",
      "😞\n",
      "😞\n",
      "Let us go play baseball\n",
      "⚾\n",
      "⚾\n",
      "This stupid grader is not working\n",
      "😞\n",
      "😞\n",
      "work is horrible\n",
      "😞\n",
      "😞\n",
      "Congratulation for having a baby\n",
      "😄\n",
      "😄\n",
      "stop pissing me off\n",
      "😞\n",
      "😞\n",
      "any suggestions for dinner\n",
      "🍴\n",
      "🍴\n",
      "I love taking breaks\n",
      "❤️\n",
      "❤️\n",
      "you brighten my day\n",
      "😄\n",
      "❤️\n",
      "I boiled rice\n",
      "🍴\n",
      "🍴\n",
      "she is a bully\n",
      "😞\n",
      "❤️\n",
      "Why are you feeling bad\n",
      "😞\n",
      "😞\n",
      "I am upset\n",
      "😞\n",
      "😞\n",
      "give me the ball\n",
      "⚾\n",
      "⚾\n",
      "My grandmother is the love of my life\n",
      "❤️\n",
      "❤️\n",
      "enjoy your game\n",
      "⚾\n",
      "😄\n",
      "valentine day is near\n",
      "😄\n",
      "❤️\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(X_test[i]))\n",
    "    print(emoji.emojize(emoji_dict[np.argmax(Y_test[i])], use_aliases=True))\n",
    "    print(emoji.emojize(emoji_dict[pred[i]], use_aliases=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
